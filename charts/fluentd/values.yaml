nameOverride: ""
fullnameOverride: ""

# DaemonSet, Deployment or StatefulSet
kind: "DaemonSet"

# # Only applicable for Deployment or StatefulSet
# replicaCount: 1

image:
  repository: "ghcr.io/log-10x/log10x-fluentd"
  pullPolicy: "IfNotPresent"
  # Overrides the image tag whose default is {{ .Chart.AppVersion }}-{{ .Values.l1x.variant }}
  tag: ""

# L1X configuration
#
# NOTE - also look at originalFluentOutput which is placed lower in this file,
# as it's needed along the base fileConfigs of this chart
#
l1x:
  # Main switch to enabled/disable l1x.
  #
  enabled: true

  # Specifies the Log10x distribution and affects which image will be used.
  # For more details, see - http://doc.log10x.com/architecture/flavors
  #
  # jit, native
  variant: jit

  # Specify your l1x license key
  license: "NO-LICENSE"

  # L1X mode - "report", "regulate" or "optimize"
  kind: "regulate"

  # Specify name for the l1x runtime
  # If empty, will use default from l1x configuration
  runtimeName:

  # Control fetching L1X config and/or symbols from github.
  # If either config.enabled or symbols.enabled are true, the deployment will setup an
  # init container to fetch config/symbols before the fluent-bit pod is live, and will share
  # the result files via a shared volume 'shared-git-volume' that's mounted to the fluent-bit
  # pod at '/etc/l1x/git'
  #
  # To learn more about the l1x github config fetcher, see:
  # https://github.com/log-10x/docker-images/tree/main/ext/github-config-fetcher
  #
  github:
    config:
      # If config.enabled is true, the init container will fetch the config from github.
      # The config will be at '/etc/l1x/git/config', and the L1X_CONFIG env var will
      # be set to point to it.
      #
      # Otherwise, the default config bundled with the fluent-bit + l1x image will be used.
      #
      enabled: false

      # Access token for GitHub.
      # To learn more, see: https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens
      #
      token: "MY-TOKEN"

      # The repo to fetch the config from
      #
      repo: "user-name/config-repo"

      # Optional - a branch to pull.
      # If omitted, the default repo branch will be used.
      # branch: "main"

    symbols:
      # If symbols.enabled is true, the init container will fetch the symbols from github.
      # The symbols will be at '/etc/l1x/git/config/data/shared/symbols', and the environment
      # variable L1X_SYMBOLS_PATH will be set to match
      #
      enabled: false

      # Access token for GitHub.
      # To learn more, see: https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens
      #
      token: "MY-TOKEN"

      # The repo to fetch the config from
      #
      repo: "user-name/symbols-repo"

      # Optional - a branch to pull.
      # If omitted, the default repo branch will be used.
      # branch: "main"

      # Optional - a sub folder inside the repo where symbols were placed.
      # If omitted, the entire repo is considered as the symbols path.
      # path: "l1x/my-app/symbols"

  # Main config files, used internally by the template to setup the correct overall fluentd configuration
  #
  fileConfigs:
    # Config files for the 'reporter' app
    #
    report:
      # Fluentd config for handling passing events into the pipeline in 'reporter' mode
      #
      00_l1x.conf: |-
        @include "#{ENV['L1X_MODULES']}/pipelines/run/modules/input/forwarder/fluentd/conf/l1x-report.conf"

      # Controls which events are emitted into the l1x 'reporter'
      # Works by creating a copy, one to send into l1x via the @L1X label, and one to the actual
      # output Fluentd will emit the events to.
      #
      # Default behavior is to emit all events to L1X, edit this section to change.
      #
      04_outputs.conf: |-
        <label @OUTPUT>
          <match **>
            @type copy
            <store>
              @type relabel
              @label @FINAL-OUTPUT
            </store>
            <store>
              @type relabel
              @label @L1X
            </store>
          </match>
        </label>

    regulate:
      # Fluentd config for handling passing events into the pipeline in 'regulator' mode
      #
      00_l1x.conf: |-
        @include "#{ENV['L1X_MODULES']}/pipelines/run/modules/input/forwarder/fluentd/conf/l1x-regulate-unix.conf"

      # Controls which events are emitted into the l1x 'regulator'
      # Works by applying the @L1X label.
      #
      # Events which aren't meant to be regulated, should have the @FINAL-OUTPUT label applied instead.
      #
      # Default behavior is to emit all events to L1X for regulating, edit this section to change.
      #
      04_outputs.conf: |-
        <label @OUTPUT>
          <match **>
            @type relabel
            @label @L1X
          </match>
        </label>

      # Routes all events coming back from L1X after being regulated to the final Fluentd output.
      #
      05_l1x_processed.conf: |-
        <label @L1X-PROCESSED>
          <match **>
            @type relabel
            @label @FINAL-OUTPUT
          </match>
        </label>

    optimize:
      # Fluentd config for handling passing events into the pipeline in 'optimizer' mode
      #
      00_l1x.conf: |-
        @include "#{ENV['L1X_MODULES']}/pipelines/run/modules/input/forwarder/fluentd/conf/l1x-optimize-unix.conf"

      # Controls which events are emitted into the l1x 'optimizer'
      # Works by applying the @L1X label.
      #
      # Events which aren't meant to be optimized, should have the @FINAL-OUTPUT label applied instead.
      #
      # Default behavior is to emit all events to L1X for optimizing, edit this section to change.
      #
      04_outputs.conf: |-
        <label @OUTPUT>
          <match **>
            @type relabel
            @label @L1X
          </match>
        </label>

      # Routes all events coming back from L1X after being optimized to the final Fluentd output.
      #
      05_l1x_processed.conf: |-
        <label @L1X-PROCESSED>
          <match **>
            @type relabel
            @label @FINAL-OUTPUT
          </match>
        </label>

    l1xLogs:
      # A Fluentd source for reading the internal l1x log.
      #
      # This is so the log can also be forwarded by Fluentd to an output destination for debug purposes.
      #
      01_l1x_sources.conf: |-
        <source>
          @type tail
          @id in_tail_l1x_internal_logs
          @label @L1X-INTERNAL
          path /var/log/l1x/*.log
          pos_file /var/log/l1x-internal.log.pos
          tag l1x-internal.*
          <parse>
            @type none
          </parse>
        </source>

  # The below config controls the outputs when l1x.enabled is set to 'true'.
  # When l1x.enabled is set to 'false', output is controlled by 'originalFluentOutput'
  #
  outputConfigs:
    # Sets the output destination for events
    #
    06_final_output.conf: |-
      <label @FINAL-OUTPUT>
        <match **>
          @type elasticsearch
          host "elasticsearch-master"
          port 9200
          path ""
          user elastic
          password changeme
          # Don't wait for elastic to start up.
          verify_es_version_at_startup false
        </match>
      </label>

    # Emitting generated l1xTemplates ('optimize' only) the l1es_dml index in elastic search.
    # This will allow the L1x Elastic app to decode optimized events.
    #
    # For more info on l1xTemplates, see http://doc.log10x.com/run/template/
    #
    # This config is based on
    # https://github.com/l1x-co/config/blob/main/pipelines/run/input/forwarder/fluentd/l1x-elastic.conf
    #
    07_l1x_templates.conf: |-
      <label @L1X-TEMPLATE>
        <match **>
          @type elasticsearch
          host "elasticsearch-master"
          port 9200
          path ""
          user elastic
          password changeme

          index_name l1es_dml
          id_key templateHash

          <buffer>
            flush_interval 10s
          </buffer>

          # Don't wait for elastic to start up.
          verify_es_version_at_startup false
        </match>
      </label>

    # Emitting the l1x internal log, change the destination if needed.
    #
    08_l1x_internal.conf: |-
      <label @L1X-INTERNAL>
        <match **>
          @type elasticsearch
          host "elasticsearch-master"
          port 9200
          path ""
          user elastic
          password changeme

          index_name l1x-internal

          # Don't wait for elastic to start up.
          verify_es_version_at_startup false
        </match>
      </label>

    # REMINDER NOTE - also look at 'originalFluentOutput' for complete configuration


## Optional array of imagePullSecrets containing private registry credentials
## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
imagePullSecrets: []

serviceAccount:
  create: true
  annotations: {}
  name: null

rbac:
  create: true

# from Kubernetes 1.25, PSP is deprecated
# See: https://kubernetes.io/blog/2022/08/23/kubernetes-v1-25-release/#pod-security-changes
# We automatically disable PSP if Kubernetes version is 1.25 or higher
podSecurityPolicy:
  enabled: true
  annotations: {}

## Security Context policies for controller pods
## See https://kubernetes.io/docs/tasks/administer-cluster/sysctl-cluster/ for
## notes on enabling and using sysctls
##
podSecurityContext: {}
  # seLinuxOptions:
  #   type: "spc_t"

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

# Configure the livecycle
# Ref: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/
lifecycle: {}
  # preStop:
  #   exec:
  #     command: ["/bin/sh", "-c", "sleep 20"]

# Configure the livenessProbe
# Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
livenessProbe:
  httpGet:
    path: /metrics
    port: metrics
  # initialDelaySeconds: 0
  # periodSeconds: 10
  # timeoutSeconds: 1
  # successThreshold: 1
  # failureThreshold: 3

# Configure the readinessProbe
# Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
readinessProbe:
  httpGet:
    path: /metrics
    port: metrics
  # initialDelaySeconds: 0
  # periodSeconds: 10
  # timeoutSeconds: 1
  # successThreshold: 1
  # failureThreshold: 3

resources: {}
  # requests:
  #   cpu: 10m
  #   memory: 128Mi
  # limits:
  #   memory: 128Mi

## only available if kind is Deployment
autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80
  ## see https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/#autoscaling-on-multiple-metrics-and-custom-metrics
  customRules: []
    # - type: Pods
    #   pods:
    #     metric:
    #       name: packets-per-second
    #     target:
    #       type: AverageValue
    #       averageValue: 1k
  ## see https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#support-for-configurable-scaling-behavior
  # behavior:
  #   scaleDown:
  #     policies:
  #       - type: Pods
  #         value: 4
  #         periodSeconds: 60
  #       - type: Percent
  #         value: 10
  #         periodSeconds: 60

# priorityClassName: "system-node-critical"

nodeSelector: {}

## Node tolerations for server scheduling to nodes with taints
## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
##
tolerations: []
# - key: null
#   operator: Exists
#   effect: "NoSchedule"

## Affinity and anti-affinity
## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
##
affinity: {}

## Annotations to be added to fluentd DaemonSet/Deployment
##
annotations: {}

## Labels to be added to fluentd DaemonSet/Deployment
##
labels: {}

## Annotations to be added to fluentd pods
##
podAnnotations: {}

## Labels to be added to fluentd pods
##
podLabels: {}

## How long (in seconds) a pods needs to be stable before progressing the deployment
##
minReadySeconds:

## How long (in seconds) a pod may take to exit (useful with lifecycle hooks to ensure lb deregistration is done)
##
terminationGracePeriodSeconds:

## Deployment strategy / DaemonSet updateStrategy
##
updateStrategy: {}
#   type: RollingUpdate
#   rollingUpdate:
#     maxUnavailable: 1

## Additional environment variables to set for fluentd pods
env: []
  # - name: "FLUENTD_CONF"
  #   value: "../../../etc/fluent/fluent.conf"
  # - name: FLUENT_ELASTICSEARCH_HOST
  #   value: "elasticsearch-master"
  # - name: FLUENT_ELASTICSEARCH_PORT
  #   value: "9200"

envFrom: []

initContainers: []

## Name of the configMap containing a custom fluentd.conf configuration file to use instead of the default.
# mainConfigMapNameOverride: ""

## Name of the configMap containing files to be placed under /etc/fluent/config.d/
## NOTE: This will replace ALL default files in the aforementioned path!
# extraFilesConfigMapNameOverride: ""

mountVarLogDirectory: true
mountDockerContainersDirectory: true

volumes: []

volumeMounts: []

## Only available if kind is StatefulSet
## Fluentd persistence
##
persistence:
  enabled: false
  storageClass: ""
  accessMode: ReadWriteOnce
  size: 10Gi

## Fluentd service
##
service:
  enabled: true
  type: "ClusterIP"
  annotations: {}
  # loadBalancerIP:
  # externalTrafficPolicy: Local
  ports: []
  # - name: "forwarder"
  #   protocol: TCP
  #   containerPort: 24224

## Prometheus Monitoring
##
metrics:
  serviceMonitor:
    enabled: false
    additionalLabels:
      release: prometheus-operator
    namespace: ""
    namespaceSelector: {}
    ## metric relabel configs to apply to samples before ingestion.
    ##
    metricRelabelings: []
    # - sourceLabels: [__name__]
    #   separator: ;
    #   regex: ^fluentd_output_status_buffer_(oldest|newest)_.+
    #   replacement: $1
    #   action: drop
    ## relabel configs to apply to samples after ingestion.
    ##
    relabelings: []
    # - sourceLabels: [__meta_kubernetes_pod_node_name]
    #   separator: ;
    #   regex: ^(.*)$
    #   targetLabel: nodename
    #   replacement: $1
    #   action: replace
    ## Additional serviceMonitor config
    ##
    # jobLabel: fluentd
    # scrapeInterval: 30s
    # scrapeTimeout: 5s
    # honorLabels: true

  prometheusRule:
    enabled: false
    additionalLabels: {}
    namespace: ""
    rules: []
    # - alert: FluentdDown
    #   expr: up{job="fluentd"} == 0
    #   for: 5m
    #   labels:
    #     context: fluentd
    #     severity: warning
    #   annotations:
    #     summary: "Fluentd Down"
    #     description: "{{ $labels.pod }} on {{ $labels.nodename }} is down"
    # - alert: FluentdScrapeMissing
    #   expr: absent(up{job="fluentd"} == 1)
    #   for: 15m
    #   labels:
    #     context: fluentd
    #     severity: warning
    #   annotations:
    #     summary: "Fluentd Scrape Missing"
    #     description: "Fluentd instance has disappeared from Prometheus target discovery"

## Grafana Monitoring Dashboard
##
dashboards:
  enabled: "true"
  namespace: ""
  labels:
    grafana_dashboard: '"1"'

## Fluentd list of plugins to install
##
plugins: []
# - fluent-plugin-out-http

## Add fluentd config files from k8s configMaps
##
configMapConfigs: []
#  - fluentd-prometheus-conf
#  - fluentd-systemd-conf

## Fluentd configurations:
##
fileConfigs:
  01_sources.conf: |-
    ## logs from podman
    <source>
      @type tail
      @id in_tail_container_logs
      @label @KUBERNETES
      path /var/log/containers/*.log
      pos_file /var/log/fluentd-containers.log.pos
      tag kubernetes.*
      read_from_head true
      <parse>
        @type multi_format
        <pattern>
          format json
          time_key time
          time_type string
          time_format "%Y-%m-%dT%H:%M:%S.%NZ"
          keep_time_key false
        </pattern>
        <pattern>
          format regexp
          expression /^(?<time>.+) (?<stream>stdout|stderr)( (.))? (?<log>.*)$/
          time_format '%Y-%m-%dT%H:%M:%S.%NZ'
          keep_time_key false
        </pattern>
      </parse>
      emit_unmatched_lines true
    </source>

    # expose metrics in prometheus format
    <source>
      @type prometheus
      bind 0.0.0.0
      port 24231
      metrics_path /metrics
    </source>

  02_filters.conf: |-
    <label @KUBERNETES>
      <match kubernetes.var.log.containers.fluentd**>
        @type relabel
        @label @FLUENT_LOG
      </match>

      # <match kubernetes.var.log.containers.**_kube-system_**>
      #   @type null
      #   @id ignore_kube_system_logs
      # </match>

      <filter kubernetes.**>
        @type kubernetes_metadata
        @id filter_kube_metadata
        skip_labels false
        skip_container_metadata false
        skip_namespace_metadata true
        skip_master_url true
      </filter>

      <match **>
        @type relabel
        @label @DISPATCH
      </match>
    </label>

  03_dispatch.conf: |-
    <label @DISPATCH>
      <filter **>
        @type prometheus
        <metric>
          name fluentd_input_status_num_records_total
          type counter
          desc The total number of incoming records
          <labels>
            tag ${tag}
            hostname ${hostname}
          </labels>
        </metric>
      </filter>

      <match **>
        @type relabel
        @label @OUTPUT
      </match>
    </label>

# Fluentd output configurations
#
# This config is only used when l1x.enabled is set to 'false', so that all events
# will be emitted directly to your output of choice.
#
originalFluentOutput:
  04_outputs.conf: |-
    <label @OUTPUT>
      <match **>
        @type elasticsearch
        host "elasticsearch-master"
        port 9200
        path ""
        user elastic
        password changeme
        # Don't wait for elastic to start up.
        verify_es_version_at_startup false
      </match>
    </label>

ingress:
  enabled: false
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    # - host: fluentd.example.tld
    - port: 9880

  tls: []
  # - secretName: fluentd-tls
  #   hosts:
  #     - fluentd.example.tld
